<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Adnane Boukhayma</h1>
        <h3 style="margin-bottom:0"><a href="#Research">Reseach,</a> <a href="#Datasets">Datasets,</a> <a href="#Teaching">Teaching</a></h3>
        <p><small>adnane.boukhayma(at)inria.fr</small>
        </p> 
        <p>
        I am a tenured research scientist (chargé de recherche) at Inria Rennes.
        Previously I was a postdoc at the University of Oxford.
        I completed my PhD before that at Inria Grenoble.
        </p>
        <p>
          <a href="https://www.inria.fr/en"><img style="height:20px" src="images/inria.png" >
          </a>&nbsp;
          <a href="https://github.com/boukhayma"><img style="height:20px" src="images/github.png" ></a>&nbsp;
          <a href="https://scholar.google.com/citations?user=ayfaw7AAAAAJ&hl=en"><img style="height:20px" src="images/google.png" ></a>
        </p>  
        <!--<img style="width:75%" src="images/seoul.png" class="center">-->
        <!--<img style="width:75%" src="images/adnane.png" >-->
        <img style="width:75%" src="images/adnane.png" > 
 

      </header>

      <section>
        <!-- <h1>News</h1> -->
        <h1 id="Research"> Research</h1>

        <img src="images/papers/proker.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">ProKeR: A Kernel Perspective on Few-Shot Adaptation of Large Vision-Language Models</h3>
        <p style="margin-bottom:0">Y. Bendou, A. Ouasfi, V. Gripon, A. Boukhayma</b><br/> 
        <i>CVPR 2025</i><br>
        <small><a href="https://ybendou.github.io/ProKeR/">Project </a>|
        <a href="https://arxiv.org/abs/2501.11175">PDF </a>|
        <a href="https://github.com/ybendou/ProKeR">Code</a></small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/sdro.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">Toward Robust Neural Reconstruction from Sparse Point Sets</h3>
        <p style="margin-bottom:0">A. Ouasfi, S. Jena, E. Marchand A. Boukhayma</b><br/> 
        <i>ECCV 2024</i><br>
        <small><a href="https://ouasfi.github.io/sdro/">Project </a>|
        <a href="https://arxiv.org/abs/2412.16361">PDF </a>|
        <a href="https://ouasfi.github.io/sdro/">Code</a></small>
        </p>
        <hr style="width:75%">
        
        <img src="images/papers/face.jpg" height="96" class="pull-left" style="margin:0px 0px 5px 0px;border-color:white;border-radius:10px">
        <h3 style="margin-bottom:0">SPARK: Self-supervised Personalized Real-time Monocular Face Capture</h3>
        <p style="margin-bottom:0">K. Baert, S. Bharadwaj, F. Castan, B. Maujean, M. Christie, V. Abrevaya, A. Boukhayma</b><br/> 
        <i>SIGGRAPH Asia 2024</i><br>
        <small><a href="https://kelianb.github.io/SPARK/">Project </a>|
        <a href="https://arxiv.org/abs/2409.07984">PDF </a>|
        <a href="https://kelianb.github.io/SPARK/">Code </a>|
        <a href="https://kelianb.github.io/SPARK/">Data</a></small>
        </p>
        <hr style="width:75%">
        
        <img src="images/papers/TnT4.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">SparseCraft: Few-Shot Neural Reconstruction through Stereopsis Guided Geometric Linearization</h3>
        <p style="margin-bottom:0">M. Younes, A. Ouasfi, A. Boukhayma</b><br/> 
        <i>ECCV 2024</i><br>
        <small><a href="https://sparsecraft.github.io/">Project </a>|
        <a href="https://arxiv.org/abs/2407.14257">PDF </a>|
        <a href="https://sparsecraft.github.io/">Code </a>|
        <a href="https://drive.google.com/file/d/1nuR1C80N8SvewFpggm3rqGQ8KghsgHIi">Data</a></small>
        </p>
        <hr style="width:75%">
        
        <img src="images/papers/nap.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">Few-Shot Unsupervised Implicit Neural Shape Representation Learning with Spatial Adversaries</h3>
        <p style="margin-bottom:0">A. Ouasfi, A. Boukhayma</b><br/> 
        <i>ICML 2024</i><br>
        <small><a href="https://arxiv.org/abs/2408.15114">PDF </a>|
        <a href="https://boukhayma.github.io">Code</a></small>
        </p>
        <hr style="width:75%">
        
        <img src="images/papers/cvpr24.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">Unsupervised Occupancy Learning from Sparse Point Cloud</h3>
        <p style="margin-bottom:0">A. Ouasfi, A. Boukhayma</b><br/> 
        <i>CVPR 2024 (Highlight)</i><br>
        <small><a href="https://arxiv.org/abs/2404.02759">PDF </a>|
        <a href="https://github.com/Ouasfi/SparseOcc">Code</a></small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/geotr.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">GeoTransfer: Generalizable Few-Shot Multi-View Reconstruction via Transfer Learning</h3>
        <p style="margin-bottom:0">S. Jena, F. Multon, A. Boukhayma<br/> 
        <i>ECCV Workshop 2024</i><br>
        <small><a href="https://shubhendu-jena.github.io/geotransfer/">Project </a>|
        <a href="https://arxiv.org/abs/2408.14724">PDF </a>|
        <a href="https://github.com/Shubhendu-Jena/Geo-Transfer">Code</a></small>
        </small>
        </p>
        <hr style="width:75%">
        
        <img src="images/papers/krr.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">Robustifying Generalizable Implicit Shape Networks with a Tunable Non-Parametric Model</h3>
        <p style="margin-bottom:0">A. Ouasfi, A. Boukhayma</b><br/> 
        <i>NeurIPS 2023</i><br>
        <small><a href="https://arxiv.org/abs/2311.12967">PDF </a>|
        <a href="https://github.com/Ouasfi/Feat-NKRR-adaptation">Code</a></small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/den1.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">Mixing-Denoising Generalizable Occupancy Networks</h3>
        <p style="margin-bottom:0">A. Ouasfi, A. Boukhayma</b><br/> 
        <i>3DV 2024</i><br>
        <small><a href="https://arxiv.org/abs/2311.12125">PDF </a>|
        <a href="https://boukhayma.github.io">Code</a></small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/hrec.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px;border-color:white;border-radius:10px">
        <h3 style="margin-bottom:0">Few-Shot Multi-Human Neural Rendering Using Geometry Constraints</h3>
        <p style="margin-bottom:0">Q. Li, V. Abrevaya, F. Multon, A. Boukhayma</b><br/> 
        <i>arXiv 2023</i><br>
        <small><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4772785">PDF </a>|
        <a href="https://boukhayma.github.io">Code</a></small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/ho.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px;border-color:white;border-radius:10px">
        <h3 style="margin-bottom:0">Contact-conditioned hand-held object reconstruction from single-view images</h3>
        <p style="margin-bottom:0">X. Wang, Y. Li, A. Boukhayma, C. Wang, M. Christie</b><br/> 
        <i>C&G 2023</i><br>
        <small><a href="https://www.sciencedirect.com/science/article/abs/pii/S009784932300078X">PDF </a></small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/lfn_pipe.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">Learning Generalizable Light Field Networks from Few Images</h3>
        <p style="margin-bottom:0">Q. Li, F. Multon, A. Boukhayma<br/> 
        <i>ICASSP 2023</i><br>
        <small><a href="https://arxiv.org/abs/2207.11757">PDF </a>|
        <a href="https://github.com/Violetsli/LightfieldRendering">Code</a></small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/fssdf.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">Few ‘Zero Level Set’-Shot Learning of Shape Signed Distance Functions in Feature Space</h3>
        <p style="margin-bottom:0">A. Ouasfi, A. Boukhayma</b><br/> 
        <i>ECCV 2022</i><br>
        <small><a href="https://arxiv.org/abs/2207.04161">PDF </a>|
        <a href="https://github.com/Ouasfi/FS-SDF">Code</a></small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/nmbg.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">Neural Mesh-Based Graphics</h3>
        <p style="margin-bottom:0">S. Jena, F. Multon, A. Boukhayma<br/> 
        <i>ECCV Workshop 2022</i><br>
        <small><a href="https://arxiv.org/abs/2208.05785">PDF </a>|
        <a href="https://github.com/Shubhendu-Jena/Neural-Mesh-Based-Graphics">Code</a></small>
        </small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/depth.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">3D Human Shape and Pose from a Single Depth Image with Deep Dense Correspondence Enabled Model Fitting</h3>
        <p style="margin-bottom:0">X. Wang, A. Boukhayma, S. Prevost, E. Desjardin, C. Loscos, F. Multon<br/> 
        <i>EG Poster 2022</i><br>
        <small><a href="https://hal.archives-ouvertes.fr/hal-03664189">PDF</a>
        </small>
        </p>
        <hr style="width:75%">            

        <img src="images/papers/dual.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">Dual Mesh Convolutional Networks for Human Shape Correspondence</h3>
        <p style="margin-bottom:0">N. Verma, A. Boukhayma, J. Verbeek, E. Boyer<br/> 
        <i>3DV 2021 (Oral)</i><br>
        <small><a href="https://arxiv.org/abs/2103.12459">PDF</a>
        </small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/def_trans.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">Neural Human Deformation Transfer</h3>
        <p style="margin-bottom:0">J. Basset, A. Boukhayma, S. Wuhrer, F. Multon, E. Boyer<br/>
        <i>3DV 2021</i><br>
        <small><a href="https://arxiv.org/abs/2109.01588">PDF</a>
        </small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/pose.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px;">
        <h3 style="margin-bottom:0">Monocular Human Shape and Pose with Dense Mesh-borne Local Image Features</h3>
        <p style="margin-bottom:0">S. Jena, F. Multon, A. Boukhayma<br/> 
        <i>FG 2021</i><br>
        <small><a href="https://arxiv.org/abs/2111.05319">PDF </a>|
        <a href="https://github.com/Shubhendu-Jena/Monocular-Human-Shape-and-Pose-with-Dense-Mesh-borne-Local-Image-Features">Code</a></small>
        </small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/cross.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px;border-color:white;border-radius:10px">
        <h3 style="margin-bottom:0">Cross-modal Deep Face Normals with Deactivable Skip Connections</h3>
        <p style="margin-bottom:0">V. Abrevaya*, A. Boukhayma*, P. Torr, E. Boyer (*equal contrib.)<br> 
        <i>CVPR 2020 (Oral)</i><br>
        <small><a href="https://arxiv.org/abs/2003.09691">PDF </a>|
        <a href="https://github.com/boukhayma/face_normals">Code</a></small>
        </p>
        <hr style="width:75%">


        <img src="images/papers/dgpose.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px;border-color:white;border-radius:10px">
        <h3 style="margin-bottom:0">DGPose: Deep Generative Models for Human Body Analysis</h3>
        <p style="margin-bottom:0">R. de Bem, A. Ghosh, T. Ajanthan, O. Miksik, A. Boukhayma, N. Siddharth, P. Torr<br> 
        <i>IJCV 2020</i><br>
        <small><a href="https://arxiv.org/abs/1804.06364">PDF</a>
        </small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/dec_face.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">A Decoupled 3D Facial Shape Model by Adversarial Training</h3>
        <p style="margin-bottom:0">V. Abrevaya, A. Boukhayma, S. Wuhrer, E. Boyer<br> 
        <i>ICCV 2019 (Oral)</i><br>
        <small><a href="https://arxiv.org/abs/1902.03619">PDF</a>
        </small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/hand.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px;border-color:white;border-radius:10px">
        <h3 style="margin-bottom:0">3D Hand Shape and Pose from Images in the Wild</h3>
        <p style="margin-bottom:0">A. Boukhayma, R. de Bem, P. Torr<br> 
        <i>CVPR 2019 (Oral)</i><br>
        <small><a href="https://arxiv.org/abs/1902.03451">PDF </a>|
        <a href="https://github.com/boukhayma/3dhand">Code</a></small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/people_images.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">A Conditional Deep Generative Model of People in Natural Images</h3>
        <p style="margin-bottom:0">R. de Bem, A. Ghosh, A. Boukhayma, T. Ajanthan, N. Siddharth, P. Torr<br>
        <i>WACV 2019</i><br>
        <small>
        <a href="https://www.robots.ox.ac.uk/~tvg/publications/2018/290.pdf">PDF</a>
        </small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/dom_part.png" height="96" class="pull-left" style="margin:0px 0px 0px 0px;border-color:white;border-radius:10px">
        <h3 style="margin-bottom:0">Domain Partitioning Network</h3>
        <p style="margin-bottom:0">B. Csaba, A. Boukhayma, V. Kulharia, A. Horváth, P. Torr<br>
        <i>arXiv 2019</i><br>
        <small>
        <a href="https://arxiv.org/abs/1902.08134">PDF</a>
        </small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/anim_synthesis.jpg" height="96" class="pull-left" style="margin:0px 0px 5px 0px;border-color:white;border-radius:10px">
        <h3 style="margin-bottom:0">Surface Motion Capture Animation Synthesis</h3>
        <p style="margin-bottom:0">A. Boukhayma, E. Boyer<br> 
        <i>TVCG 2018</i><br>
        <small>
        <a href="https://hal.inria.fr/hal-01781164/document">PDF</a>
        </small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/gpr_trans.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">Surface Motion Capture Transfer with Gaussian Process Regression</h3>
        <p style="margin-bottom:0">A. Boukhayma, J. Franco, E. Boyer<br> 
        <i>CVPR 2017</i><br>
        <small>
        <a href="https://hal.inria.fr/hal-01491386/document">PDF</a>
        </small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/var_synth.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">Controllable Variation Synthesis for Surface Motion Capture</h3>
        <p style="margin-bottom:0">A. Boukhayma, E. Boyer<br> 
        <i>3DV 2017</i><br>
        <small>
        <a href="https://hal.inria.fr/hal-01590648/document">PDF</a>
        </small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/appearance_map.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">Eigen Appearance Maps of Dynamic Shapes</h3>
        <p style="margin-bottom:0">A. Boukhayma, V. Tsiminaki, J. Franco, E. Boyer<br> 
        <i>ECCV 2016</i><br>
        <small>
        <a href="https://hal.inria.fr/hal-01348837/document">PDF </a>|
        <a href="https://hal.inria.fr/hal-01348837/file/Data_EigenAppearance.zip">Data </a>
        </small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/essential_graph.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3 style="margin-bottom:0">Video based Animation Synthesis with the Essential Graph</h3>
        <p style="margin-bottom:0">A. Boukhayma, E. Boyer<br> 
        <i>3DV 2015 (Oral)</i><br>
        <small>
        <a href="https://hal.inria.fr/hal-01212168/document">PDF </a>|
        <a href="https://hal.inria.fr/hal-01212168/file/Data.zip">Data </a>
        </small>
        </p>
        <hr style="width:75%">

        <img src="images/papers/phd.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px;border-color:white;border-radius:10px">
        <h3 style="margin-bottom:0">Surface Motion Capture Animation</h3>
        <p style="margin-bottom:0">A. Boukhayma<br> 
        <i>PhD Thesis</i><br>
        <small>
        <a href="https://tel.archives-ouvertes.fr/tel-01665203/document">PDF</a>
        </small>
        </p>
        <hr style="width:75%">
        
      </section>

      <section>  
        <h1 id="Datasets">Datasets</h1>

        <img src="images/papers/hands2.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px;border-color:white;border-radius:10px">
        <h3><a href="https://github.com/boukhayma/3dhand">
        Synthetic Rendered Hands
        </a></h3>
        <hr style="width:75%">

        <img src="images/papers/out.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px">
        <h3><a href="https://hal.inria.fr/hal-01348837/file/Data_EigenAppearance.zip">
        4D Textured Human Shapes
        </a></h3>
        <hr style="width:75%">

        <img src="images/papers/in.png" height="96" class="pull-left" style="margin:0px 0px 5px 0px;border-color:white;border-radius:10px">
        <h3><a href="https://hal.inria.fr/hal-01212168/file/Data.zip">
        4D Human Shapes
        </a></h3>
        <hr style="width:75%">       
      </section>

      <section>  
        <h1 id="Teaching">Teaching</h1>
        Coming soon..
        <hr style="width:75%">        
      </section>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
